{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏠 House Price Prediction\n",
    "\n",
    "Welcome to the **House Price Prediction** project. This notebook outlines the process of building a predictive model to estimate house prices based on various features. We'll cover data preprocessing, feature engineering, model training, evaluation, and making predictions on new data to help Lydia Doe predict the price of her inherited houses in Ames Iowa USA.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for data manipulation, model building, and evaluation\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, ElasticNetCV, LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Directory Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base data directory\n",
    "data_dir = 'data'\n",
    "\n",
    "# Define the models directory within the data directory\n",
    "models_dir = os.path.join(data_dir, 'models')\n",
    "\n",
    "# Create the models directory if it doesn't exist to store trained models and related artifacts\n",
    "os.makedirs(models_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for the datasets\n",
    "house_data_file = os.path.join(data_dir, 'house_prices_records.csv')\n",
    "inherited_houses_file = os.path.join(data_dir, 'inherited_houses.csv')\n",
    "\n",
    "# Import datasets using pandas\n",
    "house_data = pd.read_csv(house_data_file)\n",
    "inherited_houses = pd.read_csv(inherited_houses_file)\n",
    "\n",
    "# Display the shape of the datasets to understand their dimensions\n",
    "print(f\"House Data Shape: {house_data.shape}\")\n",
    "print(f\"Inherited Houses Shape: {inherited_houses.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5: Log Transformation of SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation to the 'SalePrice' to normalize its distribution\n",
    "house_data['SalePrice_Log'] = np.log1p(house_data['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6: Handle Missing Values in house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Handling missing values in house_data...\")\n",
    "\n",
    "# List of features where missing values should be filled with zero\n",
    "zero_fill_features = [\n",
    "    '2ndFlrSF', 'EnclosedPorch', 'MasVnrArea', 'WoodDeckSF',\n",
    "    'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', 'BsmtUnfSF'\n",
    "]\n",
    "\n",
    "# Fill missing values with zero for the specified features\n",
    "for feature in zero_fill_features:\n",
    "    house_data[feature].fillna(0, inplace=True)\n",
    "\n",
    "# Fill categorical features with appropriate default values\n",
    "house_data['BedroomAbvGr'].fillna(house_data['BedroomAbvGr'].mode()[0], inplace=True)\n",
    "house_data['BsmtFinType1'].fillna('None', inplace=True)\n",
    "house_data['GarageFinish'].fillna('Unf', inplace=True)\n",
    "house_data['BsmtExposure'].fillna('No', inplace=True)\n",
    "house_data['KitchenQual'].fillna('TA', inplace=True)\n",
    "\n",
    "# Fill numerical features with median values\n",
    "house_data['GarageYrBlt'].fillna(house_data['GarageYrBlt'].median(), inplace=True)\n",
    "house_data['LotFrontage'].fillna(house_data['LotFrontage'].median(), inplace=True)\n",
    "house_data['OverallQual'].fillna(house_data['OverallQual'].median(), inplace=True)\n",
    "house_data['OverallCond'].fillna(house_data['OverallCond'].median(), inplace=True)\n",
    "house_data['YearBuilt'].fillna(house_data['YearBuilt'].median(), inplace=True)\n",
    "house_data['YearRemodAdd'].fillna(house_data['YearRemodAdd'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7: Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Encoding categorical features in house_data...\")\n",
    "\n",
    "# Define ordinal mappings for categorical features to convert them into numerical values\n",
    "ordinal_mappings = {\n",
    "    'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtExposure': {'No': 0, 'Mn': 1, 'Av': 2, 'Gd': 3, 'None': 0},\n",
    "    'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "}\n",
    "\n",
    "# Apply the ordinal mappings to the respective columns\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    if col in house_data.columns:\n",
    "        house_data[col] = house_data[col].map(mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 8: Identify and Transform Skewed Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical features in the dataset\n",
    "numeric_feats = house_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Calculate skewness for each numerical feature\n",
    "skewness = house_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "\n",
    "# Select features with absolute skewness greater than 0.75\n",
    "skewed_features = skewness[abs(skewness) > 0.75].index.tolist()\n",
    "\n",
    "print(f\"Skewed Features: {skewed_features}\")\n",
    "\n",
    "# Apply log or box-cox transformation to reduce skewness\n",
    "print(\"Transforming skewed features in house_data...\")\n",
    "lam_dict = {}  # Dictionary to store lambda values for box-cox transformation\n",
    "for feat in skewed_features:\n",
    "    if (house_data[feat] <= 0).any():\n",
    "        # If any value is less than or equal to zero, apply log1p transformation\n",
    "        house_data[feat] = np.log1p(house_data[feat])\n",
    "    else:\n",
    "        try:\n",
    "            # Apply box-cox transformation and store lambda\n",
    "            transformed_data, lam = boxcox(house_data[feat])\n",
    "            house_data[feat] = transformed_data\n",
    "            lam_dict[feat] = lam\n",
    "        except ValueError:\n",
    "            # If box-cox fails, fallback to log1p transformation\n",
    "            house_data[feat] = np.log1p(house_data[feat])\n",
    "\n",
    "# Save the skewed features and lambda values for future use\n",
    "with open(os.path.join(models_dir, 'skewed_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(skewed_features, f)\n",
    "with open(os.path.join(models_dir, 'lam_dict.pkl'), 'wb') as f:\n",
    "    pickle.dump(lam_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 8: Identify and Transform Skewed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical features in the dataset\n",
    "numeric_feats = house_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Calculate skewness for each numerical feature\n",
    "skewness = house_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "\n",
    "# Select features with absolute skewness greater than 0.75\n",
    "skewed_features = skewness[abs(skewness) > 0.75].index.tolist()\n",
    "\n",
    "print(f\"Skewed Features: {skewed_features}\")\n",
    "\n",
    "# Apply log or box-cox transformation to reduce skewness\n",
    "print(\"Transforming skewed features in house_data...\")\n",
    "lam_dict = {}  # Dictionary to store lambda values for box-cox transformation\n",
    "for feat in skewed_features:\n",
    "    if (house_data[feat] <= 0).any():\n",
    "        # If any value is less than or equal to zero, apply log1p transformation\n",
    "        house_data[feat] = np.log1p(house_data[feat])\n",
    "    else:\n",
    "        try:\n",
    "            # Apply box-cox transformation and store lambda\n",
    "            transformed_data, lam = boxcox(house_data[feat])\n",
    "            house_data[feat] = transformed_data\n",
    "            lam_dict[feat] = lam\n",
    "        except ValueError:\n",
    "            # If box-cox fails, fallback to log1p transformation\n",
    "            house_data[feat] = np.log1p(house_data[feat])\n",
    "\n",
    "# Save the skewed features and lambda values for future use\n",
    "with open(os.path.join(models_dir, 'skewed_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(skewed_features, f)\n",
    "with open(os.path.join(models_dir, 'lam_dict.pkl'), 'wb') as f:\n",
    "    pickle.dump(lam_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 9: Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performing feature engineering in house_data...\")\n",
    "\n",
    "# Create new features by combining existing ones\n",
    "house_data['TotalSF'] = house_data['TotalBsmtSF'] + house_data['1stFlrSF'] + house_data['2ndFlrSF']\n",
    "house_data['Qual_TotalSF'] = house_data['OverallQual'] * house_data['TotalSF']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 10: Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing data for modeling...\")\n",
    "\n",
    "# Define the feature list based on metadata\n",
    "feature_list = [\n",
    "    '1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtExposure', 'BsmtFinType1',\n",
    "    'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageArea', 'GarageFinish',\n",
    "    'GarageYrBlt', 'GrLivArea', 'KitchenQual', 'LotArea', 'LotFrontage',\n",
    "    'MasVnrArea', 'EnclosedPorch', 'OpenPorchSF', 'OverallCond', 'OverallQual',\n",
    "    'WoodDeckSF', 'YearBuilt', 'YearRemodAdd'\n",
    "]\n",
    "\n",
    "# Ensure that only the specified features are included in X\n",
    "X = house_data.drop(['SalePrice', 'SalePrice_Log'], axis=1, errors='ignore')\n",
    "X = X[feature_list]\n",
    "\n",
    "# Define the target variable\n",
    "y = house_data['SalePrice_Log']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 11: Feature Selection Using Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performing feature selection using Random Forest...\")\n",
    "\n",
    "# Initialize Random Forest Regressor for feature importance\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Extract feature importances and sort them\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Select the top 20 features based on importance\n",
    "selected_features = importances[:20].index.tolist()\n",
    "\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "# Save the selected features for future reference\n",
    "with open(os.path.join(models_dir, 'selected_features.pkl'), 'wb') as f:\n",
    "    pickle.dump(selected_features, f)\n",
    "\n",
    "# Update X to include only the selected features\n",
    "X = X[selected_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 12: Split Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting data into training and test sets...\")\n",
    "\n",
    "# Split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 13: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scaling features...\")\n",
    "\n",
    "# Initialize StandardScaler for feature normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, os.path.join(models_dir, 'scaler.joblib'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 14: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training models...\")\n",
    "\n",
    "# Define a dictionary of models to train\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': RidgeCV(alphas=np.logspace(-4, 4, 10)),\n",
    "    'ElasticNet': ElasticNetCV(\n",
    "        alphas=np.logspace(-4, -0.5, 30), l1_ratio=0.5, cv=5, max_iter=10000\n",
    "    ),\n",
    "    'Lasso Regression': LassoCV(\n",
    "        alphas=np.logspace(-4, -0.5, 30), cv=5, max_iter=10000\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=3,\n",
    "        min_samples_leaf=5, max_features=0.8, random_state=42\n",
    "    ),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=None, max_features='sqrt',\n",
    "        min_samples_leaf=2, random_state=42\n",
    "    ),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=5,\n",
    "        min_child_weight=3, subsample=0.8, colsample_bytree=0.8, random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store evaluation results\n",
    "results = {'Model': [], 'MAE': [], 'RMSE': [], 'R² Score': []}\n",
    "\n",
    "# Iterate through each model, train it, evaluate, and save the results\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)  # Train the model on scaled training data\n",
    "    \n",
    "    # Define a filename for saving the trained model\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}_model.joblib\"\n",
    "    \n",
    "    # Save the trained model to the models directory\n",
    "    joblib.dump(model, os.path.join(models_dir, model_filename))\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(np.expm1(y_test), np.expm1(predictions))\n",
    "    rmse = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(predictions)))\n",
    "    r2 = r2_score(np.expm1(y_test), np.expm1(predictions))\n",
    "    \n",
    "    # Append the results to the dictionary\n",
    "    results['Model'].append(name)\n",
    "    results['MAE'].append(mae)\n",
    "    results['RMSE'].append(rmse)\n",
    "    results['R² Score'].append(r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 15: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results dictionary to a pandas DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the evaluation results to a CSV file in the models directory\n",
    "results_df.to_csv(os.path.join(models_dir, 'model_evaluation.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 16: Process Inherited Houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing inherited houses...\")\n",
    "\n",
    "# Handle missing values in inherited_houses dataset\n",
    "\n",
    "# Fill missing values with zero for the specified features\n",
    "for feature in zero_fill_features:\n",
    "    inherited_houses[feature].fillna(0, inplace=True)\n",
    "\n",
    "# Fill categorical features with appropriate default values\n",
    "inherited_houses['BedroomAbvGr'].fillna(\n",
    "    house_data['BedroomAbvGr'].mode()[0], inplace=True\n",
    ")\n",
    "inherited_houses['BsmtFinType1'].fillna('None', inplace=True)\n",
    "inherited_houses['GarageFinish'].fillna('Unf', inplace=True)\n",
    "inherited_houses['BsmtExposure'].fillna('No', inplace=True)\n",
    "inherited_houses['KitchenQual'].fillna('TA', inplace=True)\n",
    "\n",
    "# Fill numerical features with median values from house_data\n",
    "inherited_houses['GarageYrBlt'].fillna(\n",
    "    house_data['GarageYrBlt'].median(), inplace=True\n",
    ")\n",
    "inherited_houses['LotFrontage'].fillna(\n",
    "    house_data['LotFrontage'].median(), inplace=True\n",
    ")\n",
    "inherited_houses['OverallQual'].fillna(\n",
    "    house_data['OverallQual'].median(), inplace=True\n",
    ")\n",
    "inherited_houses['OverallCond'].fillna(\n",
    "    house_data['OverallCond'].median(), inplace=True\n",
    ")\n",
    "inherited_houses['YearBuilt'].fillna(\n",
    "    house_data['YearBuilt'].median(), inplace=True\n",
    ")\n",
    "inherited_houses['YearRemodAdd'].fillna(\n",
    "    house_data['YearRemodAdd'].median(), inplace=True\n",
    ")\n",
    "\n",
    "# Encode categorical features using the same mappings as house_data\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    if col in inherited_houses.columns:\n",
    "        inherited_houses[col] = inherited_houses[col].map(mapping)\n",
    "\n",
    "# Feature engineering on inherited_houses\n",
    "inherited_houses['TotalSF'] = (\n",
    "    inherited_houses['TotalBsmtSF']\n",
    "    + inherited_houses['1stFlrSF']\n",
    "    + inherited_houses['2ndFlrSF']\n",
    ")\n",
    "inherited_houses['Qual_TotalSF'] = (\n",
    "    inherited_houses['OverallQual'] * inherited_houses['TotalSF']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 17: Transform Skewed Features in inherited_houses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Transforming skewed features in inherited_houses...\")\n",
    "\n",
    "# Iterate through each skewed feature and apply the same transformation as house_data\n",
    "for feat in skewed_features:\n",
    "    if feat in inherited_houses.columns:\n",
    "        if (inherited_houses[feat] <= 0).any():\n",
    "            # Apply log1p transformation if any value is <= 0\n",
    "            inherited_houses[feat] = np.log1p(inherited_houses[feat])\n",
    "        else:\n",
    "            lam = lam_dict.get(feat)\n",
    "            if lam is not None:\n",
    "                try:\n",
    "                    # Apply box-cox transformation using the stored lambda\n",
    "                    inherited_houses[feat] = boxcox(inherited_houses[feat], lam)\n",
    "                except ValueError:\n",
    "                    # Fallback to log1p if box-cox fails\n",
    "                    inherited_houses[feat] = np.log1p(inherited_houses[feat])\n",
    "            else:\n",
    "                # Fallback to log1p if lambda is not available\n",
    "                inherited_houses[feat] = np.log1p(inherited_houses[feat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 18: Ensure Feature Matching\n",
    "\n",
    "# Reindex inherited_houses to include only the selected features, filling missing with zero\n",
    "inherited_houses = inherited_houses.reindex(columns=selected_features, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Scaling Inherited Houses Features\n",
    "\n",
    "# Scale the inherited_houses data using the previously fitted scaler\n",
    "inherited_houses_scaled = scaler.transform(inherited_houses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 20: Make Predictions on Inherited Houses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Making predictions on inherited houses...\")\n",
    "\n",
    "# Initialize an empty DataFrame to store predictions\n",
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each trained model to make predictions\n",
    "for name, model in models.items():\n",
    "    # Predict log sale prices\n",
    "    predictions_log = model.predict(inherited_houses_scaled)\n",
    "    \n",
    "    # Convert log predictions back to original scale\n",
    "    predictions_actual = np.expm1(predictions_log)\n",
    "    \n",
    "    # Handle infinite or NaN values by replacing them with the mean of the predictions\n",
    "    predictions_actual = np.where(\n",
    "        np.isfinite(predictions_actual), predictions_actual, np.nan\n",
    "    )\n",
    "    predictions_actual = np.nan_to_num(\n",
    "        predictions_actual, nan=np.nanmean(predictions_actual)\n",
    "    )\n",
    "    \n",
    "    # Add the predictions to the DataFrame\n",
    "    predictions_df[name] = predictions_actual\n",
    "\n",
    "# Save the predictions to a CSV file in the models directory\n",
    "predictions_df.to_csv(\n",
    "    os.path.join(models_dir, 'inherited_houses_predictions.csv'), index=False\n",
    ")\n",
    "\n",
    "print(\"Predictions saved to 'inherited_houses_predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 21: Display Predictions for Inherited Houses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the predictions for inherited houses\n",
    "print(\"Predictions for Inherited Houses:\")\n",
    "print(predictions_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎉 Conclusion\n",
    "\n",
    "In this project, we successfully built and evaluated multiple machine learning models to predict house prices based on various features. The steps included data preprocessing, handling missing values, encoding categorical variables, feature engineering, feature selection, model training, and evaluation. Additionally, we applied the trained models to make predictions on a separate dataset of inherited houses.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- **Data Preprocessing:** Proper handling of missing values and encoding of categorical features are crucial for model performance.\n",
    "- **Feature Engineering:** Creating new features can provide additional insights and improve model accuracy.\n",
    "- **Model Evaluation:** Comparing multiple models using metrics like MAE, RMSE, and R² Score helps in selecting the best-performing model.\n",
    "- **Scalability:** Saving models and preprocessing objects ensures that the pipeline can be reused for future predictions without retraining.\n",
    "\n",
    "**Next Steps:**\n",
    "- **Hyperparameter Tuning:** Further optimize model parameters to enhance performance.\n",
    "- **Cross-Validation:** Implement cross-validation techniques to ensure model robustness.\n",
    "- **Deployment:** Consider deploying the best-performing model as an API or integrate it into a web application for real-time predictions.\n",
    "\n",
    "Thank you for following along this project! Feel free to reach out for any questions or further discussions.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
